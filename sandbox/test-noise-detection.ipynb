{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b82186a-ec03-4984-869f-bd037960cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f21d17fb-253e-4a43-ba58-ba61e3490aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_image(folder_path, max_files=-1):\n",
    "    image_paths = glob(folder_path + \"*.tif\")[:max_files]\n",
    "    first_time = True\n",
    "    for path in image_paths:\n",
    "        print(path)\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        if first_time:\n",
    "            first_time = False\n",
    "            mean_img = img.astype(np.float64)\n",
    "        else:\n",
    "            mean_img += img\n",
    "    return (mean_img/len(image_paths)).astype(np.uint8)\n",
    "\n",
    "def detect_colored_noise(image, bright_thresh_rgb=(15, 15, 15), dark_thresh=2, min_area=4):\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    diff = cv2.absdiff(image, blurred)\n",
    "    b, g, r = cv2.split(diff)\n",
    "    hot_b = np.uint8(b > bright_thresh_rgb[0]) * 255\n",
    "    hot_g = np.uint8(g > bright_thresh_rgb[1]) * 255\n",
    "    hot_r = np.uint8(r > bright_thresh_rgb[2]) * 255\n",
    "    hot_rgb = cv2.bitwise_or(hot_r, cv2.bitwise_or(hot_g, hot_b))\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    diff_dark = blurred_gray.astype(np.int16) - gray.astype(np.int16)\n",
    "    mask_dark = np.uint8(diff_dark > dark_thresh) * 255\n",
    "    mask_dark = _filter_by_area(mask_dark, min_area)\n",
    "    mask_dark = cv2.morphologyEx(mask_dark, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))\n",
    "    print(\"hot pixels, r: {}\".format(hot_r[hot_r>0].size))\n",
    "    print(\"hot pixels, g: {}\".format(hot_g[hot_g>0].size))\n",
    "    print(\"hot pixels, b: {}\".format(hot_b[hot_b>0].size))\n",
    "    print(\"hot pixels, rgb: {}\".format(hot_rgb[hot_rgb>0].size))\n",
    "    print(\"dark pixels: {}\".format(mask_dark[mask_dark>0].size))\n",
    "    return hot_rgb, (hot_b, hot_g, hot_r), mask_dark\n",
    "    return mask_bright_rgb, mask_dark\n",
    "\n",
    "def _filter_by_area(mask, min_area):\n",
    "    \"\"\"Filtra le maschere per area minima.\"\"\"\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_mask = np.zeros_like(mask)\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > min_area:\n",
    "            cv2.drawContours(filtered_mask, [cnt], -1, 255, -1)\n",
    "    return filtered_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0427de84-0376-470f-b003-1ede71a0a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_defective_pixels(image, defect_mask, kernel_size=3, method='mean'):\n",
    "    if len(image.shape) == 3:\n",
    "        corrected = image.copy()\n",
    "        for c in range(3):\n",
    "            channel = image[:, :, c]\n",
    "            defect_channel = defect_mask > 0\n",
    "            corrected[:, :, c] = _correct_channel(channel, defect_channel, kernel_size, method)\n",
    "    else:\n",
    "        corrected = _correct_channel(image, defect_mask > 0, kernel_size, method)\n",
    "    return corrected\n",
    "\n",
    "def _correct_channel(channel, defect_mask, kernel_size, method):\n",
    "    corrected = channel.copy()\n",
    "    defect_coords = np.argwhere(defect_mask)\n",
    "    for y, x in defect_coords:\n",
    "        neighborhood = channel[\n",
    "            max(0, y - kernel_size//2):min(channel.shape[0], y + kernel_size//2 + 1),\n",
    "            max(0, x - kernel_size//2):min(channel.shape[1], x + kernel_size//2 + 1)\n",
    "        ]        \n",
    "        valid_pixels = neighborhood[neighborhood != 0]  # Opzionale: escludi altri pixel difettosi se necessario\n",
    "        if len(valid_pixels) > 0:\n",
    "            if method == 'mean':\n",
    "                corrected[y, x] = np.mean(valid_pixels)\n",
    "            elif method == 'median':\n",
    "                corrected[y, x] = np.median(valid_pixels)\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcae07eb-e9b5-401e-be8f-d4bb3e24b6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8501.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8502.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8503.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8504.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8505.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8506.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8507.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8508.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8509.tif\n",
      "E:/Focus stacking/2025-04-19 - Hemiptera/A/src\\_MG_8510.tif\n",
      "hot pixels, r: 8\n",
      "hot pixels, g: 6\n",
      "hot pixels, b: 21\n",
      "hot pixels, rgb: 24\n",
      "dark pixels: 46\n"
     ]
    }
   ],
   "source": [
    "input_path = \"E:/Focus stacking/2025-04-19 - Hemiptera/A/src/\"\n",
    "mean_img = mean_image(input_path, 10)\n",
    "hot_rgb, (hot_b, hot_g, hot_r), mask_dark = detect_colored_noise(mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40728e9d-e073-4448-ad3c-065cbc7b5a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_path = \"E:/Focus stacking/2025-04-19 - Hemiptera/A/noise-map/\"\n",
    "cv2.imwrite(out_path + \"hot_b.png\", hot_b)\n",
    "cv2.imwrite(out_path + \"hot_g.png\", hot_g)\n",
    "cv2.imwrite(out_path + \"hot_r.png\", hot_r)\n",
    "cv2.imwrite(out_path + \"hot_rgb.png\", hot_rgb)\n",
    "cv2.imwrite(out_path + \"dark.png\", mask_dark)\n",
    "cv2.imwrite(out_path + \"mean_img.tif\", mean_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "164ef2be-664a-49b6-b8d4-ce77855e1d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.imread(input_path + \"/_MG_8521.tif\")\n",
    "defect_mask = cv2.imread(out_path + \"hot_rgb.png\", cv2.IMREAD_GRAYSCALE)  # Maschera binaria\n",
    "corrected_image = correct_defective_pixels(image, defect_mask, kernel_size=5, method='median')\n",
    "cv2.imwrite(out_path + \"orig.tif\", image)\n",
    "cv2.imwrite(out_path + \"corr.tif\", corrected_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de827da8-8134-431a-bb2a-ba48b4d68738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438023f-c23d-4a6b-b9ab-339df18e8a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
